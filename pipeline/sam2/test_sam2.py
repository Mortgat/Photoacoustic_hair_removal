import torch
from sam2.build_sam import build_sam2_video_predictor
import os

# 1. On dÃ©finit les chemins vers le cerveau de SAM 2
# SAM 2 vient avec ses fichiers de configuration par dÃ©faut quand on l'installe via pip
config_file = "configs/sam2.1/sam2.1_hiera_l.yaml" 
checkpoint_path = "checkpoints/sam2.1_hiera_large.pt"

print("ğŸš€ DÃ©marrage de l'initialisation de SAM 2...")

# 2. On vÃ©rifie la configuration GPU
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"âœ… GPU dÃ©tectÃ© : {torch.cuda.get_device_name(0)}")
    # Optimisation vitale pour l'imagerie mÃ©dicale avec Ampere/Ada Lovelace
    torch.autocast("cuda", dtype=torch.bfloat16).__enter__()
    if torch.cuda.get_device_properties(0).major >= 8:
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
else:
    device = torch.device("cpu")
    print("âš ï¸ Attention, GPU non trouvÃ©. SAM 2 va Ãªtre extrÃªmement lent sur CPU.")

# 3. Chargement du modÃ¨le
try:
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Le fichier {checkpoint_path} est introuvable. L'as-tu bien tÃ©lÃ©chargÃ© ?")
        
    predictor = build_sam2_video_predictor(config_file, checkpoint_path, device=device)
    print("ğŸ‰ SUCCÃˆS : SAM 2 Large est chargÃ© dans la VRAM de ton GPU et prÃªt Ã  analyser tes donnÃ©es !")
except Exception as e:
    print(f"âŒ Erreur lors du chargement : {e}")